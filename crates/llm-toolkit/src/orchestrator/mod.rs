//! Orchestrator - Agent swarm coordination for complex LLM workflows.
//!
//! This module provides a policy-driven orchestrator that coordinates multiple agents
//! to accomplish complex tasks. Unlike traditional workflow engines with rigid type systems,
//! the orchestrator uses natural language blueprints and LLM-based strategy generation
//! for maximum flexibility.
//!
//! # Design Philosophy
//!
//! The orchestrator avoids "photorealistic complexity" - the temptation to model
//! agent interactions with strict Actor-like message passing and complex state management.
//! Instead, it leverages LLM flexibility to:
//!
//! - Generate execution strategies ad-hoc from blueprints
//! - Adapt to errors with tactical or full redesign
//! - Inject context naturally into agent intents
//!
//! # Example
//!
//! ```rust,ignore
//! use llm_toolkit::orchestrator::{Orchestrator, BlueprintWorkflow, OrchestrationStatus};
//! use llm_toolkit::agent::ClaudeCodeAgent;
//!
//! #[tokio::main]
//! async fn main() {
//!     let blueprint = BlueprintWorkflow::new(r#"
//!         Technical Article Workflow:
//!         1. Analyze topic and create outline
//!         2. Research each section
//!         3. Write full article
//!         4. Generate title and summary
//!     "#.to_string());
//!
//!     let mut orchestrator = Orchestrator::new(blueprint);
//!     orchestrator.add_agent(Box::new(ClaudeCodeAgent::new()));
//!
//!     let result = orchestrator.execute(
//!         "Write an article about Rust async programming"
//!     ).await;
//!
//!     match result.status {
//!         OrchestrationStatus::Success => {
//!             println!("Success! Steps: {}, Redesigns: {}",
//!                 result.steps_executed, result.redesigns_triggered);
//!             if let Some(output) = result.final_output {
//!                 println!("{}", output);
//!             }
//!         }
//!         OrchestrationStatus::Failure => {
//!             eprintln!("Failed: {:?}", result.error_message);
//!         }
//!     }
//! }
//! ```

pub mod blueprint;
pub mod config;
pub mod error;
pub mod parallel;
mod parallel_orchestrator;
pub mod strategy;

// Prompt definitions require both derive (ToPrompt macro) and agent (for usage)
#[cfg(all(feature = "derive", feature = "agent"))]
pub mod prompts;

pub use blueprint::BlueprintWorkflow;
pub use config::OrchestratorConfig;
pub use error::OrchestratorError;
pub use parallel_orchestrator::{
    OrchestrationState, ParallelOrchestrationResult, ParallelOrchestrator,
};
pub use strategy::{
    AggregationMode, LoopAggregation, LoopBlock, LoopType, RedesignStrategy, StrategyInstruction,
    StrategyMap, StrategyStep, TerminateInstruction,
};

use crate::agent::{Agent, AgentAdapter, AgentOutput, DynamicAgent};
use serde::{Deserialize, Serialize};
use serde_json::Value as JsonValue;
use std::collections::HashMap;
use std::time::Duration;
use tracing::{debug, error, info, info_span, instrument, warn};

/// TypeMarker trait for identifying output types in orchestrator context.
///
/// This trait enables type-based retrieval of orchestrator outputs without
/// relying on step IDs, which are dynamically generated by the strategy LLM.
///
/// # Example
///
/// ```ignore
/// use llm_toolkit::orchestrator::TypeMarker;
/// use serde::{Serialize, Deserialize};
///
/// #[derive(Serialize, Deserialize, TypeMarker)]
/// pub struct HighConceptResponse {
///     pub reasoning: String,
///     pub high_concept: String,
/// }
///
/// // TypeMarker automatically adds:
/// // - __type field with default value "HighConceptResponse"
/// // - type_marker() method returning "HighConceptResponse"
///
/// // Usage with Orchestrator:
/// let result = orchestrator.get_typed_output::<HighConceptResponse>()?;
/// ```
pub trait TypeMarker {
    /// The unique type identifier used in the `__type` field.
    const TYPE_NAME: &'static str;

    /// Returns the type marker for this type.
    fn type_marker() -> &'static str {
        Self::TYPE_NAME
    }
}

/// Status of the orchestration execution.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub enum OrchestrationStatus {
    Success,
    Failure,
}

/// Structured result returned by the orchestrator.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OrchestrationResult {
    pub status: OrchestrationStatus,
    pub final_output: Option<JsonValue>,
    pub steps_executed: usize,
    pub redesigns_triggered: usize,
    pub loops_executed: usize,
    pub terminations_triggered: usize,
    pub error_message: Option<String>,
}

/// Result of executing a sequence of instructions (internal).
enum InstructionExecutionResult {
    /// Normal completion with final output
    Completed(JsonValue),
    /// Early termination triggered
    Terminated(JsonValue),
}

#[cfg(feature = "agent")]
use crate::agent::impls::{ClaudeCodeAgent, ClaudeCodeJsonAgent, InnerValidatorAgent};

/// The orchestrator coordinates multiple agents to execute complex workflows.
///
/// The orchestrator maintains:
/// - A `BlueprintWorkflow` describing the intended process
/// - A registry of available agents
/// - Dynamically generated execution strategies
/// - Runtime context for inter-agent communication
pub struct Orchestrator {
    /// The workflow blueprint (reference material for strategy generation).
    #[cfg(any(not(feature = "agent"), feature = "derive"))]
    blueprint: BlueprintWorkflow,

    /// Available agents, keyed by their name.
    /// Uses DynamicAgent for type erasure, allowing heterogeneous agent types.
    agents: HashMap<String, Box<dyn DynamicAgent>>,

    /// Internal JSON agent for structured strategy generation.
    /// Output type is StrategyMap for generating execution strategies.
    #[cfg(feature = "agent")]
    internal_json_agent: Box<dyn Agent<Output = StrategyMap>>,

    /// Internal string agent for intent generation and redesign decisions.
    /// Output type is String for generating prompts and making decisions.
    #[cfg(feature = "agent")]
    internal_agent: Box<dyn Agent<Output = String>>,

    /// The currently active execution strategy.
    strategy_map: Option<StrategyMap>,

    /// Runtime context storing intermediate results as JSON values.
    context: HashMap<String, JsonValue>,

    /// The original task description (stored for regeneration).
    current_task: Option<String>,

    /// Configuration for orchestrator execution behavior.
    config: OrchestratorConfig,
}

impl Orchestrator {
    /// Creates a new Orchestrator with a given blueprint.
    ///
    /// Uses default internal agents (ClaudeCodeAgent and ClaudeCodeJsonAgent).
    /// Both internal agents are automatically wrapped with RetryAgent (max 3 retries)
    /// to ensure robustness in strategy generation and redesign decisions.
    /// InnerValidatorAgent is automatically registered as a fallback validator.
    #[cfg(feature = "agent")]
    pub fn new(blueprint: BlueprintWorkflow) -> Self {
        use crate::agent::impls::RetryAgent;

        let mut orchestrator = Self {
            blueprint,
            agents: HashMap::new(),
            internal_json_agent: Box::new(RetryAgent::new(ClaudeCodeJsonAgent::new(), 3)),
            internal_agent: Box::new(RetryAgent::new(ClaudeCodeAgent::new(), 3)),
            strategy_map: None,
            context: HashMap::new(),
            current_task: None,
            config: OrchestratorConfig::default(),
        };

        // Register InnerValidatorAgent as a standard agent
        orchestrator.add_agent(InnerValidatorAgent::new());

        orchestrator
    }

    /// Creates a new Orchestrator with custom internal agents.
    ///
    /// This allows you to inject mock or alternative agents for testing or custom LLM backends.
    /// **IMPORTANT**: For production use, **wrap your agents with RetryAgent** before passing them
    /// to ensure robustness in strategy generation and redesign decisions. The orchestrator cannot
    /// automatically wrap boxed trait objects.
    /// InnerValidatorAgent is automatically registered as a fallback validator.
    ///
    /// # Arguments
    ///
    /// * `blueprint` - The workflow blueprint
    /// * `internal_agent` - Agent for string outputs (intent generation, redesign decisions).
    ///   **Recommended**: Wrap with RetryAgent
    /// * `internal_json_agent` - Agent for StrategyMap generation.
    ///   **Recommended**: Wrap with RetryAgent
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// use llm_toolkit::orchestrator::{BlueprintWorkflow, Orchestrator};
    /// use llm_toolkit::agent::impls::{RetryAgent, ClaudeCodeAgent, ClaudeCodeJsonAgent};
    ///
    /// let blueprint = BlueprintWorkflow::new("My workflow".to_string());
    ///
    /// // Recommended: Wrap with RetryAgent for robustness
    /// let orchestrator = Orchestrator::with_internal_agents(
    ///     blueprint,
    ///     Box::new(RetryAgent::new(ClaudeCodeAgent::new(), 3)),
    ///     Box::new(RetryAgent::new(ClaudeCodeJsonAgent::new(), 3)),
    /// );
    /// ```
    #[cfg(feature = "agent")]
    pub fn with_internal_agents(
        blueprint: BlueprintWorkflow,
        internal_agent: Box<dyn Agent<Output = String>>,
        internal_json_agent: Box<dyn Agent<Output = StrategyMap>>,
    ) -> Self {
        let mut orchestrator = Self {
            blueprint,
            agents: HashMap::new(),
            internal_json_agent,
            internal_agent,
            strategy_map: None,
            context: HashMap::new(),
            current_task: None,
            config: OrchestratorConfig::default(),
        };

        // Register InnerValidatorAgent as a standard agent
        orchestrator.add_agent(InnerValidatorAgent::new());

        orchestrator
    }

    /// Creates a new Orchestrator without the internal agent (for testing).
    #[cfg(not(feature = "agent"))]
    pub fn new(blueprint: BlueprintWorkflow) -> Self {
        Self {
            blueprint,
            agents: HashMap::new(),
            strategy_map: None,
            context: HashMap::new(),
            current_task: None,
            config: OrchestratorConfig::default(),
        }
    }

    /// Sets the orchestrator configuration.
    ///
    /// # Arguments
    ///
    /// * `config` - The configuration to use
    ///
    /// # Examples
    ///
    /// ```ignore
    /// use llm_toolkit::orchestrator::OrchestratorConfig;
    ///
    /// let config = OrchestratorConfig {
    ///     max_step_remediations: 5,
    ///     ..Default::default()
    /// };
    ///
    /// let mut orchestrator = Orchestrator::new(blueprint);
    /// orchestrator.set_config(config);
    /// ```
    pub fn set_config(&mut self, config: OrchestratorConfig) {
        self.config = config;
    }

    /// Returns a reference to the current configuration.
    pub fn config(&self) -> &OrchestratorConfig {
        &self.config
    }

    /// Sets a predefined execution strategy, bypassing automatic strategy generation.
    ///
    /// When a strategy is set using this method, `execute()` will skip the strategy
    /// generation phase and directly execute the provided steps. This is useful for:
    /// - Reusing known-good strategies
    /// - Testing specific execution paths
    /// - Implementing custom strategy generation logic
    ///
    /// # Arguments
    ///
    /// * `strategy` - The StrategyMap to execute
    ///
    /// # Examples
    ///
    /// ```ignore
    /// use llm_toolkit::orchestrator::{StrategyMap, StrategyStep};
    ///
    /// let mut strategy = StrategyMap::new("Write article".to_string());
    /// strategy.add_step(StrategyStep::new(
    ///     "step_1".to_string(),
    ///     "Create outline".to_string(),
    ///     "ClaudeCodeAgent".to_string(),
    ///     "Create an outline for: {{task}}".to_string(),
    ///     "Article outline".to_string(),
    /// ));
    ///
    /// orchestrator.set_strategy_map(strategy);
    /// let result = orchestrator.execute("Rust ownership").await;
    /// ```
    pub fn set_strategy_map(&mut self, strategy: StrategyMap) {
        self.strategy_map = Some(strategy);
    }

    /// Returns a reference to the current strategy map, if one exists.
    ///
    /// This can be either a strategy that was set via `set_strategy_map()` or
    /// one that was automatically generated by `execute()`.
    ///
    /// # Returns
    ///
    /// `Some(&StrategyMap)` if a strategy exists, `None` otherwise.
    ///
    /// # Examples
    ///
    /// ```ignore
    /// if let Some(strategy) = orchestrator.strategy_map() {
    ///     println!("Strategy has {} steps", strategy.steps.len());
    /// }
    /// ```
    pub fn strategy_map(&self) -> Option<&StrategyMap> {
        self.strategy_map.as_ref()
    }

    /// Sets the maximum number of remediations allowed per step.
    ///
    /// This is a convenience method that modifies the configuration in place.
    ///
    /// # Arguments
    ///
    /// * `max` - Maximum number of remediations (redesigns/retries) per step
    ///
    /// # Examples
    ///
    /// ```ignore
    /// let mut orchestrator = Orchestrator::new(blueprint);
    /// orchestrator.set_max_step_remediations(5);
    /// ```
    pub fn set_max_step_remediations(&mut self, max: usize) {
        self.config.max_step_remediations = max;
    }

    /// Sets the maximum total number of redesigns allowed for the entire workflow.
    ///
    /// This is a convenience method that modifies the configuration in place.
    ///
    /// # Arguments
    ///
    /// * `max` - Maximum total number of redesigns
    ///
    /// # Examples
    ///
    /// ```ignore
    /// let mut orchestrator = Orchestrator::new(blueprint);
    /// orchestrator.set_max_total_redesigns(15);
    /// ```
    pub fn set_max_total_redesigns(&mut self, max: usize) {
        self.config.max_total_redesigns = max;
    }

    /// Sets the minimum interval between step executions.
    ///
    /// This provides proactive rate limiting by introducing a delay after each step execution,
    /// preventing burst API calls that could trigger 429 (Too Many Requests) errors.
    ///
    /// This is a convenience method that modifies the configuration in place.
    ///
    /// # Arguments
    ///
    /// * `interval` - Minimum delay between steps (e.g., `Duration::from_millis(500)`)
    ///
    /// # Examples
    ///
    /// ```ignore
    /// use std::time::Duration;
    ///
    /// let mut orchestrator = Orchestrator::new(blueprint);
    /// orchestrator.set_min_step_interval(Duration::from_millis(500));
    /// ```
    pub fn set_min_step_interval(&mut self, interval: Duration) {
        self.config.min_step_interval = interval;
    }

    /// Adds an agent to the orchestrator's registry.
    ///
    /// Accepts any agent with any output type. The agent will be automatically
    /// wrapped in an `AgentAdapter` for type erasure.
    ///
    /// # Example
    ///
    /// ```ignore
    /// #[derive(Agent)]
    /// #[agent(expertise = "...", output = "MyCustomType")]
    /// struct MyAgent;
    ///
    /// orchestrator.add_agent(MyAgent);
    /// ```
    pub fn add_agent<T>(&mut self, agent: impl Agent<Output = T> + 'static)
    where
        T: Serialize + serde::de::DeserializeOwned + 'static,
    {
        let adapter = AgentAdapter::new(agent);
        let name = adapter.name();
        self.agents.insert(name, Box::new(adapter));
    }

    /// Adds an agent with ToPrompt support to the orchestrator's registry.
    ///
    /// When the output type implements `ToPrompt`, the orchestrator will automatically
    /// use the prompt representation for context management instead of plain JSON.
    /// This provides better LLM understanding of complex types like enums with descriptions.
    ///
    /// # Example
    ///
    /// ```ignore
    /// use llm_toolkit::{ToPrompt, Agent};
    ///
    /// #[derive(ToPrompt, Serialize, Deserialize)]
    /// pub enum AnalysisResult {
    ///     /// The topic is technically sound
    ///     Approved,
    ///     /// Needs revision
    ///     NeedsRevision,
    /// }
    ///
    /// #[derive(Agent)]
    /// #[agent(expertise = "...", output = "AnalysisResult")]
    /// struct AnalyzerAgent;
    ///
    /// orchestrator.add_agent_with_to_prompt(AnalyzerAgent);
    /// ```
    #[cfg(feature = "agent")]
    pub fn add_agent_with_to_prompt<T>(&mut self, agent: impl Agent<Output = T> + 'static)
    where
        T: Serialize + serde::de::DeserializeOwned + crate::prompt::ToPrompt + 'static,
    {
        let adapter = AgentAdapter::with_to_prompt(agent, |output: &T| output.to_prompt());
        let name = adapter.name();
        self.agents.insert(name, Box::new(adapter));
    }

    /// Returns a reference to a dynamic agent by name.
    pub fn get_agent(&self, name: &str) -> Option<&dyn DynamicAgent> {
        self.agents.get(name).map(|boxed| &**boxed)
    }

    /// Returns a list of all available agent names.
    pub fn list_agents(&self) -> Vec<String> {
        self.agents.keys().cloned().collect()
    }

    /// Returns a formatted string describing all available agents and their expertise.
    #[cfg(feature = "agent")]
    pub fn format_agent_list(&self) -> String {
        self.agents
            .iter()
            .map(|(name, agent)| format!("- {}: {}", name, agent.expertise()))
            .collect::<Vec<_>>()
            .join("\n")
    }

    /// Returns a formatted string describing all available agents and their expertise.
    #[cfg(not(feature = "agent"))]
    pub fn format_agent_list(&self) -> String {
        self.agents
            .iter()
            .map(|(name, agent)| format!("- {}: {}", name, agent.expertise()))
            .collect::<Vec<_>>()
            .join("\n")
    }

    /// Returns a reference to the orchestrator's runtime context.
    ///
    /// The context contains intermediate results from executed steps, stored as JSON values.
    /// Keys follow the pattern:
    /// - `step_{step_id}_output`: JSON representation of step output
    /// - `step_{step_id}_output_prompt`: ToPrompt representation (if available)
    ///
    /// # Examples
    ///
    /// ```ignore
    /// let context = orchestrator.context();
    /// if let Some(output) = context.get("step_1_output") {
    ///     println!("Step 1 output: {}", output);
    /// }
    /// ```
    pub fn context(&self) -> &HashMap<String, JsonValue> {
        &self.context
    }

    /// Returns a mutable reference to the execution context.
    ///
    /// This allows direct modification of the context, which is useful for testing
    /// or manually injecting outputs.
    pub fn context_mut(&mut self) -> &mut HashMap<String, JsonValue> {
        &mut self.context
    }

    /// Returns the output of a specific step by step_id.
    ///
    /// This is a convenience method for accessing step outputs from the context.
    ///
    /// # Arguments
    ///
    /// * `step_id` - The step ID (e.g., "step_1", "step_2")
    ///
    /// # Returns
    ///
    /// The JSON output of the step, or `None` if the step hasn't been executed yet.
    ///
    /// # Examples
    ///
    /// ```ignore
    /// // After executing a workflow
    /// if let Some(concept) = orchestrator.get_step_output("step_1") {
    ///     // Deserialize if you know the type
    ///     let concept: HighConceptResponse = serde_json::from_value(concept.clone())?;
    /// }
    /// ```
    pub fn get_step_output(&self, step_id: &str) -> Option<&JsonValue> {
        self.context.get(&format!("step_{}_output", step_id))
    }

    /// Returns the ToPrompt representation of a step's output, if available.
    ///
    /// This returns the human-readable prompt version of the output, which is only
    /// available if the output type implements `ToPrompt` and the agent was registered
    /// with `add_agent_with_to_prompt()`.
    ///
    /// # Arguments
    ///
    /// * `step_id` - The step ID (e.g., "step_1", "step_2")
    ///
    /// # Returns
    ///
    /// The prompt representation as a string, or `None` if not available.
    ///
    /// # Examples
    ///
    /// ```ignore
    /// // Get human-readable version of step output
    /// if let Some(prompt) = orchestrator.get_step_output_prompt("step_1") {
    ///     println!("Step 1 output (human-readable):\n{}", prompt);
    /// }
    /// ```
    pub fn get_step_output_prompt(&self, step_id: &str) -> Option<&str> {
        self.context
            .get(&format!("step_{}_output_prompt", step_id))
            .and_then(|v| v.as_str())
    }

    /// Returns all step outputs as a map of step_id to JSON value.
    ///
    /// This filters the context to only include step outputs (not prompt versions).
    ///
    /// # Returns
    ///
    /// A HashMap where keys are step IDs and values are the JSON outputs.
    ///
    /// # Examples
    ///
    /// ```ignore
    /// let all_outputs = orchestrator.get_all_step_outputs();
    /// for (step_id, output) in all_outputs {
    ///     println!("{}: {:?}", step_id, output);
    /// }
    /// ```
    pub fn get_all_step_outputs(&self) -> HashMap<String, &JsonValue> {
        self.context
            .iter()
            .filter_map(|(key, value)| {
                if key.starts_with("step_")
                    && key.ends_with("_output")
                    && !key.ends_with("_output_prompt")
                {
                    // Extract step_id from "step_{step_id}_output"
                    key.strip_prefix("step_")
                        .and_then(|s| s.strip_suffix("_output"))
                        .map(|step_id| (step_id.to_string(), value))
                } else {
                    None
                }
            })
            .collect()
    }

    /// Returns a typed output from the orchestrator context using the TypeMarker trait.
    ///
    /// This method searches for an output with a matching `__type` field and deserializes
    /// it into the requested type. This is the recommended way to retrieve orchestrator
    /// outputs, as it doesn't depend on dynamically-generated step IDs.
    ///
    /// # Type Parameters
    ///
    /// * `T` - The output type, which must implement `TypeMarker` and `DeserializeOwned`
    ///
    /// # Returns
    ///
    /// The deserialized output of type `T`, or an error if:
    /// - No output with matching `__type` was found
    /// - Deserialization failed
    ///
    /// # Examples
    ///
    /// ```ignore
    /// use llm_toolkit::orchestrator::TypeMarker;
    /// use serde::{Serialize, Deserialize};
    ///
    /// #[derive(Serialize, Deserialize, TypeMarker)]
    /// pub struct HighConceptResponse {
    ///     pub reasoning: String,
    ///     pub high_concept: String,
    /// }
    ///
    /// // After executing the orchestrator
    /// let concept = orchestrator.get_typed_output::<HighConceptResponse>()?;
    /// println!("High concept: {}", concept.high_concept);
    /// ```
    pub fn get_typed_output<T>(&self) -> Result<T, OrchestratorError>
    where
        T: TypeMarker + serde::de::DeserializeOwned,
    {
        let type_name = T::type_marker();

        // Find the value with matching __type field
        let value = self
            .context
            .values()
            .find(|v| v.get("__type").and_then(|t| t.as_str()) == Some(type_name))
            .ok_or_else(|| {
                OrchestratorError::ExecutionFailed(format!(
                    "No output found with __type = \"{}\"",
                    type_name
                ))
            })?;

        // Deserialize into the requested type
        serde_json::from_value(value.clone()).map_err(|e| {
            OrchestratorError::ExecutionFailed(format!(
                "Failed to deserialize output with __type = \"{}\": {}",
                type_name, e
            ))
        })
    }

    /// Executes the workflow with the given task description.
    ///
    /// This is the main entry point for orchestration. The orchestrator will:
    /// 1. Generate a strategy map from the blueprint and available agents (unless already set)
    /// 2. Execute each step in sequence
    /// 3. Handle errors with adaptive redesign strategies
    /// 4. Return a structured result with execution details
    ///
    /// # Strategy Generation
    ///
    /// If a strategy has been set via `set_strategy_map()`, that strategy will be used
    /// directly and strategy generation will be skipped. Otherwise, a new strategy will
    /// be automatically generated from the blueprint.
    ///
    /// # Arguments
    ///
    /// * `task` - A natural language description of what needs to be accomplished
    ///
    /// # Returns
    ///
    /// An `OrchestrationResult` containing:
    /// - Status (Success/Failure)
    /// - Final output (if successful)
    /// - Number of steps executed
    /// - Number of redesigns triggered
    /// - Error message (if failed)
    ///
    /// # Examples
    ///
    /// ```ignore
    /// // Automatic strategy generation (default behavior)
    /// let result = orchestrator.execute("Write article about Rust").await;
    ///
    /// // Using predefined strategy
    /// orchestrator.set_strategy_map(my_strategy);
    /// let result = orchestrator.execute("Write article about Rust").await;
    /// ```
    #[instrument(skip(self), fields(task = %task))]
    pub async fn execute(&mut self, task: &str) -> OrchestrationResult {
        info!("Starting orchestrator execution for task: {}", task);

        // Store task for potential regeneration
        self.current_task = Some(task.to_string());

        // Phase 1: Generate strategy (only if not already set)
        if self.strategy_map.is_none() {
            debug!("No strategy set, generating from blueprint");
            if let Err(e) = self.generate_strategy(task).await {
                error!("Strategy generation failed: {}", e);
                return OrchestrationResult {
                    status: OrchestrationStatus::Failure,
                    final_output: None,
                    steps_executed: 0,
                    redesigns_triggered: 0,
                    loops_executed: 0,
                    terminations_triggered: 0,
                    error_message: Some(e.to_string()),
                };
            }
        } else {
            info!(
                "Using predefined strategy with {} steps",
                self.strategy_map.as_ref().unwrap().steps.len()
            );
        }

        // Phase 2: Execute strategy
        match self.execute_strategy().await {
            Ok((
                final_output,
                steps_executed,
                redesigns_triggered,
                loops_executed,
                terminations_triggered,
            )) => {
                info!("Orchestrator execution completed successfully");
                OrchestrationResult {
                    status: OrchestrationStatus::Success,
                    final_output: Some(final_output),
                    steps_executed,
                    redesigns_triggered,
                    loops_executed,
                    terminations_triggered,
                    error_message: None,
                }
            }
            Err(e) => {
                error!("Orchestrator execution failed: {}", e);
                OrchestrationResult {
                    status: OrchestrationStatus::Failure,
                    final_output: None,
                    steps_executed: 0,
                    redesigns_triggered: 0,
                    loops_executed: 0,
                    terminations_triggered: 0,
                    error_message: Some(e.to_string()),
                }
            }
        }
    }

    /// Generates an execution strategy from the blueprint, agents, and task.
    ///
    /// Uses the internal LLM agent to analyze the task, available agents,
    /// and blueprint to generate an optimal execution strategy.
    #[cfg(feature = "agent")]
    async fn generate_strategy(&mut self, task: &str) -> Result<(), OrchestratorError> {
        use crate::prompt::ToPrompt;
        use prompts::StrategyGenerationRequest;

        debug!("Generating strategy for task: {}", task);

        if self.agents.is_empty() {
            return Err(OrchestratorError::StrategyGenerationFailed(
                "No agents available".to_string(),
            ));
        }

        // Build the prompt using llm-toolkit's ToPrompt
        // Serialize context for strategy LLM to understand available placeholders
        let user_context = if !self.context.is_empty() {
            serde_json::to_string_pretty(&self.context).ok()
        } else {
            None
        };

        let request = StrategyGenerationRequest::new(
            task.to_string(),
            self.format_agent_list(),
            self.blueprint.description.clone(),
            self.blueprint.graph.clone(),
            user_context,
            self.config.enable_validation,
        );

        let prompt = request.to_prompt();

        debug!("Strategy generation prompt:\n{}", prompt);

        // Call internal JSON agent to generate strategy
        let strategy_map = self
            .internal_json_agent
            .execute(prompt.into())
            .await
            .map_err(|e| OrchestratorError::StrategyGenerationFailed(e.to_string()))?;

        info!("Generated strategy with {} steps", strategy_map.steps.len());

        self.strategy_map = Some(strategy_map);
        Ok(())
    }

    /// Generates an execution strategy and returns it without executing.
    ///
    /// This is useful for:
    /// - Saving the strategy to a file for later reuse
    /// - Inspecting the generated strategy before execution
    /// - Using the strategy as a template for similar tasks
    ///
    /// # Example
    ///
    /// ```rust,no_run
    /// use llm_toolkit::orchestrator::{
    ///     BlueprintWorkflow,
    ///     Orchestrator,
    ///     OrchestrationStatus,
    ///     StrategyMap,
    /// };
    ///
    /// async fn example() -> Result<(), Box<dyn std::error::Error>> {
    ///     let blueprint = BlueprintWorkflow::new("Document workflow".to_string());
    ///     let mut orchestrator = Orchestrator::new(blueprint);
    ///
    ///     // Generate strategy without executing
    ///     let strategy = orchestrator
    ///         .generate_strategy_only("Process documents")
    ///         .await?;
    ///
    ///     // Save to file
    ///     let json = serde_json::to_string_pretty(&strategy)?;
    ///     std::fs::write("my_workflow.json", json)?;
    ///
    ///     // Later: Load and execute
    ///     let json = std::fs::read_to_string("my_workflow.json")?;
    ///     let strategy: StrategyMap = serde_json::from_str(&json)?;
    ///     orchestrator.set_strategy_map(strategy);
    ///
    ///     let result = orchestrator.execute("Process documents").await;
    ///     assert!(matches!(result.status, OrchestrationStatus::Success));
    ///     Ok(())
    /// }
    /// ```
    #[cfg(feature = "agent")]
    pub async fn generate_strategy_only(
        &mut self,
        task: &str,
    ) -> Result<StrategyMap, OrchestratorError> {
        self.generate_strategy(task).await?;
        Ok(self.strategy_map.clone().unwrap())
    }

    /// Generates an execution strategy (stub for non-derive feature).
    #[cfg(not(all(feature = "agent", feature = "derive")))]
    async fn generate_strategy(&mut self, task: &str) -> Result<(), OrchestratorError> {
        debug!("Generating strategy for task (stub mode): {}", task);

        // Stub: Create a simple single-step strategy
        let mut strategy = StrategyMap::new(task.to_string());

        // If we have agents, assign the first one
        if let Some((agent_name, _agent)) = self.agents.iter().next() {
            let step = StrategyStep::new(
                "step_1".to_string(),
                "Execute the task".to_string(),
                agent_name.clone(),
                task.to_string(),
                "Result of the task".to_string(),
            );
            strategy.add_step(step);
        } else {
            return Err(OrchestratorError::StrategyGenerationFailed(
                "No agents available".to_string(),
            ));
        }

        self.strategy_map = Some(strategy);
        Ok(())
    }

    /// Extracts placeholders from intent template (e.g., {{ concept_content }}).
    fn extract_placeholders(template: &str) -> Vec<String> {
        let mut placeholders = Vec::new();
        let mut chars = template.chars().peekable();

        while let Some(c) = chars.next() {
            if c == '{' && chars.peek() == Some(&'{') {
                chars.next(); // consume second '{'

                // Extract content between {{ and }}
                let mut placeholder = String::new();
                let mut found_end = false;

                while let Some(inner_c) = chars.next() {
                    if inner_c == '}' && chars.peek() == Some(&'}') {
                        chars.next(); // consume second '}'
                        found_end = true;
                        break;
                    }
                    placeholder.push(inner_c);
                }

                if found_end {
                    let placeholder = placeholder.trim().to_string();
                    if !placeholder.is_empty() && !placeholders.contains(&placeholder) {
                        placeholders.push(placeholder);
                    }
                }
            }
        }

        placeholders
    }

    /// Formats context as a readable string for prompts.
    #[cfg(feature = "agent")]
    fn format_context(&self, context: &HashMap<String, JsonValue>) -> String {
        if context.is_empty() {
            return "No context available yet.".to_string();
        }

        context
            .iter()
            .filter_map(|(key, value)| {
                // Skip _prompt versions in the listing (they'll be used as replacements)
                if key.ends_with("_output_prompt") {
                    return None;
                }

                // If there's a _prompt version, prefer it
                let display_value = if let Some(prompt_key) = key.strip_suffix("_output") {
                    let prompt_key_full = format!("{}_output_prompt", prompt_key);
                    if let Some(JsonValue::String(prompt_str)) = context.get(&prompt_key_full) {
                        // Use prompt representation
                        if prompt_str.len() > 500 {
                            format!("{}... (truncated)", &prompt_str[..500])
                        } else {
                            prompt_str.clone()
                        }
                    } else {
                        // Fallback to JSON representation
                        let value_str =
                            serde_json::to_string(value).unwrap_or_else(|_| "null".to_string());
                        if value_str.len() > 200 {
                            format!("{}... (truncated)", &value_str[..200])
                        } else {
                            value_str
                        }
                    }
                } else {
                    // Not a step output, use as-is
                    let value_str =
                        serde_json::to_string(value).unwrap_or_else(|_| "null".to_string());
                    if value_str.len() > 200 {
                        format!("{}... (truncated)", &value_str[..200])
                    } else {
                        value_str
                    }
                };

                Some(format!("- {}: {}", key, display_value))
            })
            .collect::<Vec<_>>()
            .join("\n")
    }

    /// Formats completed steps for redesign prompts.
    #[cfg(feature = "agent")]
    fn format_completed_steps(&self, up_to_index: usize) -> String {
        if let Some(strategy) = &self.strategy_map {
            strategy
                .steps
                .iter()
                .take(up_to_index)
                .enumerate()
                .map(|(i, step)| {
                    let output = self
                        .context
                        .get(&format!("step_{}_output", step.step_id))
                        .cloned()
                        .unwrap_or_else(|| JsonValue::String("(no output)".to_string()));

                    // Convert JSON value to string
                    let output_str =
                        serde_json::to_string(&output).unwrap_or_else(|_| "null".to_string());

                    format!(
                        "Step {}: {}\n  Agent: {}\n  Output: {}\n",
                        i + 1,
                        step.description,
                        step.assigned_agent,
                        if output_str.len() > 100 {
                            format!("{}...", &output_str[..100])
                        } else {
                            output_str
                        }
                    )
                })
                .collect::<Vec<_>>()
                .join("\n")
        } else {
            "No completed steps".to_string()
        }
    }

    /// Builds an optimized intent prompt using LLM or fast path template substitution.
    ///
    /// This method supports two paths:
    /// 1. **Fast path (deterministic):** When all placeholders in the intent template
    ///    can be resolved from context and `enable_fast_path_intent_generation` is enabled,
    ///    uses simple template substitution without LLM calls.
    /// 2. **LLM path:** When placeholders cannot be fully resolved or fast path is disabled,
    ///    uses LLM to generate a high-quality prompt specifically tailored for the assigned agent.
    #[cfg(feature = "agent")]
    async fn build_intent(
        &self,
        step: &StrategyStep,
        context: &HashMap<String, JsonValue>,
    ) -> Result<String, OrchestratorError> {
        // Fast path: Check if we can use simple template substitution
        if self.config.enable_fast_path_intent_generation {
            let placeholders = Self::extract_placeholders(&step.intent_template);
            // Check if all placeholders can be resolved (supports dot notation like step_1_output.field)
            let all_resolved = placeholders.iter().all(|p| {
                let first_token = p.split('.').next().unwrap_or(p);
                context.contains_key(first_token)
            });

            if all_resolved {
                debug!(
                    "Using fast path for step {} (all {} placeholders resolved)",
                    step.step_id,
                    placeholders.len()
                );

                use crate::prompt::render_prompt;

                // Use minijinja for template rendering
                let intent = render_prompt(&step.intent_template, context)
                    .map_err(|e| OrchestratorError::TemplateRenderError(e.to_string()))?;

                return Ok(intent);
            }
        }

        // LLM path: Complex intent generation
        debug!(
            "Using LLM-based intent generation for step {} (fast_path={}, unresolved placeholders or complex case)",
            step.step_id, self.config.enable_fast_path_intent_generation
        );

        use crate::prompt::ToPrompt;
        use prompts::IntentGenerationRequest;

        // Get agent expertise
        let agent = self
            .agents
            .get(&step.assigned_agent)
            .ok_or_else(|| OrchestratorError::AgentNotFound(step.assigned_agent.clone()))?;

        let request = IntentGenerationRequest::new(
            step.description.clone(),
            step.expected_output.clone(),
            agent.expertise().to_string(),
            step.intent_template.clone(),
            self.format_context(context),
        );

        let prompt = request.to_prompt();

        debug!("Generating intent for step: {}", step.step_id);

        // Use internal agent to generate the intent
        let intent = self.internal_agent.execute(prompt.into()).await?;

        Ok(intent)
    }

    /// Builds intent (stub for non-derive feature).
    #[cfg(not(all(feature = "agent", feature = "derive")))]
    async fn build_intent(
        &self,
        step: &StrategyStep,
        context: &HashMap<String, JsonValue>,
    ) -> Result<String, OrchestratorError> {
        // Simple template substitution as fallback
        let mut intent = step.intent_template.clone();

        for (key, value) in context {
            let placeholder = format!("{{{}}}", key);
            let value_str = serde_json::to_string(value).unwrap_or_else(|_| "null".to_string());
            intent = intent.replace(&placeholder, &value_str);
        }

        Ok(intent)
    }

    /// Executes the current strategy step by step.
    ///
    /// Includes context injection, intent generation, and error handling with redesign.
    ///
    /// # Error Recovery with Limits
    ///
    /// The orchestrator implements two-level circuit breakers:
    /// - **Step-level**: `max_step_remediations` limits retries per individual step
    /// - **Total-level**: `max_total_redesigns` limits redesigns across entire workflow
    ///
    /// When a step fails:
    /// 1. Increment step's failure counter
    /// 2. Check if step limit exceeded → return error if so
    /// 3. Check if total limit exceeded → return error if so
    /// 4. Determine redesign strategy (Retry/TacticalRedesign/FullRegenerate)
    /// 5. Execute chosen strategy and continue
    ///
    /// # Returns
    ///
    /// Returns (final_output, steps_executed, redesigns_triggered, loops_executed, terminations_triggered).
    #[instrument(skip(self))]
    async fn execute_strategy(
        &mut self,
    ) -> Result<(JsonValue, usize, usize, usize, usize), OrchestratorError> {
        // Check strategy exists
        if self.strategy_map.is_none() {
            return Err(OrchestratorError::no_strategy());
        }

        // Migrate legacy steps to elements if needed
        if let Some(ref mut strategy) = self.strategy_map {
            strategy.migrate_legacy_steps();
        }

        // Check if we should use the new instruction-based execution path
        let use_new_path = self
            .strategy_map
            .as_ref()
            .map(|s| !s.elements.is_empty())
            .unwrap_or(false);

        if use_new_path {
            // New execution path: use execute_instructions() for Loop/Terminate support
            return self.execute_strategy_with_instructions().await;
        }

        // Legacy execution path: use step-by-step execution with redesign support
        let mut final_result = JsonValue::Null;
        let mut step_index = 0;
        let mut steps_executed = 0;
        let mut redesigns_triggered = 0;
        let loops_executed = 0;
        let terminations_triggered = 0;
        let mut step_remediation_count: HashMap<usize, usize> = HashMap::new();

        loop {
            // Get current strategy info
            let (step_count, goal, step) = {
                let strategy = self.strategy_map.as_ref().unwrap();
                if step_index >= strategy.steps.len() {
                    break; // All steps completed
                }
                (
                    strategy.steps.len(),
                    strategy.goal.clone(),
                    strategy.steps[step_index].clone(),
                )
            };

            let step_span = info_span!(
                "orchestrator_step",
                step_index,
                step_description = %step.description,
                assigned_agent = %step.assigned_agent
            );
            let _enter = step_span.enter();

            info!(
                "Executing step {}/{}: {}",
                step_index + 1,
                step_count,
                step.description
            );

            // Build intent using template rendering with full context
            let intent = self.build_intent(&step, &self.context).await?;

            debug!("Generated intent:\n{}", intent);

            // Execute agent
            let agent = self
                .agents
                .get(&step.assigned_agent)
                .ok_or_else(|| OrchestratorError::AgentNotFound(step.assigned_agent.clone()))?;

            match agent.execute_dynamic(intent.into()).await {
                Ok(agent_output) => {
                    // Unwrap AgentOutput to get the JsonValue
                    let output = match agent_output {
                        AgentOutput::Success(json_value) => json_value,
                        AgentOutput::RequiresApproval { .. } => {
                            return Err(OrchestratorError::ExecutionFailed(
                                "Agent requires approval but orchestrator does not support HIL"
                                    .to_string(),
                            ));
                        }
                    };

                    info!("Step {} completed successfully", step_index + 1);

                    // Store JSON result in context with default key
                    self.context
                        .insert(format!("step_{}_output", step.step_id), output.clone());

                    // Store with custom output_key if specified (for easier reference)
                    if let Some(ref output_key) = step.output_key {
                        self.context.insert(output_key.clone(), output.clone());
                    }

                    // Store prompt version if available (for ToPrompt implementations)
                    if let Some(prompt_str) = agent.try_to_prompt(&output) {
                        debug!("Storing prompt representation for step {}", step.step_id);
                        self.context.insert(
                            format!("step_{}_output_prompt", step.step_id),
                            JsonValue::String(prompt_str.clone()),
                        );

                        // Also store prompt version with output_key if specified
                        if let Some(ref output_key) = step.output_key {
                            self.context.insert(
                                format!("{}_prompt", output_key),
                                JsonValue::String(prompt_str),
                            );
                        }
                    }

                    // Update previous_output for convenience (commonly used in templates)
                    self.context
                        .insert("previous_output".to_string(), output.clone());

                    final_result = output;
                    steps_executed += 1;
                    step_index += 1;

                    // Apply min_step_interval delay if configured (skip for the last step)
                    let strategy = self.strategy_map.as_ref().unwrap();
                    if step_index < strategy.steps.len() && !self.config.min_step_interval.is_zero()
                    {
                        debug!(
                            "Waiting {:?} before next step (rate limiting)",
                            self.config.min_step_interval
                        );
                        tokio::time::sleep(self.config.min_step_interval).await;
                    }
                }
                Err(e) => {
                    warn!(error = ?e, "Step {} failed", step_index + 1);

                    // Increment step remediation count
                    // This counts the number of failures for this specific step.
                    // Example: If step 2 fails 3 times, step_remediation_count[2] = 3
                    let remediation_count = step_remediation_count.entry(step_index).or_insert(0);
                    *remediation_count += 1;

                    // Check step-level remediation limit
                    // Example: If max_step_remediations=3 and this is the 3rd failure,
                    // the step has been attempted 3 times total (initial + 2 retries),
                    // so we stop here.
                    if *remediation_count >= self.config.max_step_remediations {
                        error!(
                            "Step {} exceeded maximum remediation attempts ({})",
                            step_index + 1,
                            self.config.max_step_remediations
                        );
                        return Err(OrchestratorError::MaxStepRemediationsExceeded {
                            step_index,
                            max_remediations: self.config.max_step_remediations,
                        });
                    }

                    // Check total redesign limit
                    // Note: redesigns_triggered is incremented AFTER strategy selection,
                    // so we check BEFORE incrementing. This means:
                    // - Initial strategy execution: redesigns_triggered = 0 (not counted)
                    // - After 10 redesigns: redesigns_triggered = 10 → stops here
                    // Result: max_total_redesigns=10 allows 11 total executions
                    if redesigns_triggered >= self.config.max_total_redesigns {
                        error!(
                            "Total redesigns exceeded maximum limit ({})",
                            self.config.max_total_redesigns
                        );
                        return Err(OrchestratorError::MaxTotalRedesignsExceeded(
                            self.config.max_total_redesigns,
                        ));
                    }

                    // Determine redesign strategy
                    match self
                        .determine_redesign_strategy(&e, step_index, &goal)
                        .await?
                    {
                        RedesignStrategy::Retry => {
                            info!("Retrying step {}", step_index + 1);
                            redesigns_triggered += 1;
                            // Loop will retry the same step
                            continue;
                        }
                        RedesignStrategy::TacticalRedesign => {
                            info!("Performing tactical redesign from step {}", step_index + 1);
                            redesigns_triggered += 1;
                            self.tactical_redesign(&e, step_index).await?;
                            // Retry from the same index with new strategy
                            continue;
                        }
                        RedesignStrategy::FullRegenerate => {
                            info!("Performing full strategy regeneration");
                            redesigns_triggered += 1;
                            self.full_regenerate(&e, step_index).await?;
                            // Reset to beginning with new strategy
                            step_index = 0;
                            // Clear context to start fresh
                            self.context.clear();
                            // Clear step remediation counts on full regeneration
                            // This is important: When we regenerate the entire strategy,
                            // step indices may change (step 0 might become a different task),
                            // so we reset all step-level counters to start fresh.
                            step_remediation_count.clear();
                            continue;
                        }
                    }
                }
            }
        }

        Ok((
            final_result,
            steps_executed,
            redesigns_triggered,
            loops_executed,
            terminations_triggered,
        ))
    }

    /// Executes the strategy using the new instruction-based path (for Loop/Terminate support).
    ///
    /// This method handles execution when `strategy.elements` is not empty.
    /// Unlike the legacy path, this supports Loop and Terminate instructions.
    #[instrument(skip(self))]
    async fn execute_strategy_with_instructions(
        &mut self,
    ) -> Result<(JsonValue, usize, usize, usize, usize), OrchestratorError> {
        let instructions = {
            let strategy = self.strategy_map.as_ref().unwrap();
            strategy.elements.clone()
        };

        // Validate strategy (reject nested loops)
        if let Some(ref strategy) = self.strategy_map {
            strategy
                .validate()
                .map_err(OrchestratorError::invalid_blueprint)?;
        }

        let mut steps_executed = 0;
        let mut loops_executed = 0;
        let mut terminations_triggered = 0;

        // Execute instructions
        let result = self
            .execute_instructions(
                &instructions,
                &mut steps_executed,
                &mut loops_executed,
                &mut terminations_triggered,
            )
            .await?;

        // Extract final output based on result type
        let final_output = match result {
            InstructionExecutionResult::Completed(output) => output,
            InstructionExecutionResult::Terminated(output) => {
                info!("Workflow terminated early via Terminate instruction");
                output
            }
        };

        // Return (final_output, steps_executed, redesigns_triggered, loops_executed, terminations_triggered)
        // Note: redesigns_triggered is always 0 in the new path (no redesign support yet)
        Ok((
            final_output,
            steps_executed,
            0,
            loops_executed,
            terminations_triggered,
        ))
    }

    /// Evaluates a condition template against the current context.
    ///
    /// Returns `true` if the template renders to "true" (case-insensitive, trimmed),
    /// `false` otherwise or if the template is None.
    fn evaluate_condition_template(
        &self,
        template: &Option<String>,
        context: &HashMap<String, JsonValue>,
    ) -> Result<bool, OrchestratorError> {
        match template {
            None => Ok(false),
            Some(template_str) => {
                use crate::prompt::render_prompt;

                let rendered = render_prompt(template_str, context)
                    .map_err(|e| OrchestratorError::TemplateRenderError(e.to_string()))?;

                let result = rendered.trim().eq_ignore_ascii_case("true");
                debug!(
                    "Condition template '{}' rendered to '{}' -> {}",
                    template_str, rendered, result
                );
                Ok(result)
            }
        }
    }

    /// Aggregates loop iteration results based on the aggregation mode.
    ///
    /// Retrieves all iteration results from context and combines them according to the mode:
    /// - `LastSuccess`: Returns the last iteration's output
    /// - `FirstSuccess`: Returns the first iteration's output (iter_0)
    /// - `CollectAll`: Returns all iterations as a JSON array
    fn aggregate_loop_results(
        &self,
        loop_id: &str,
        mode: &AggregationMode,
        iterations_executed: usize,
    ) -> Result<JsonValue, OrchestratorError> {
        use crate::orchestrator::strategy::AggregationMode;

        match mode {
            AggregationMode::LastSuccess => {
                // Return the last iteration's output
                if iterations_executed == 0 {
                    return Ok(JsonValue::Null);
                }

                let last_iteration_key =
                    format!("loop_{}_iter_{}", loop_id, iterations_executed - 1);
                let result = self
                    .context
                    .get(&last_iteration_key)
                    .cloned()
                    .unwrap_or(JsonValue::Null);

                debug!("Aggregated (LastSuccess): {}", last_iteration_key);
                Ok(result)
            }

            AggregationMode::FirstSuccess => {
                // Return the first iteration's output
                if iterations_executed == 0 {
                    return Ok(JsonValue::Null);
                }

                let first_iteration_key = format!("loop_{}_iter_0", loop_id);
                let result = self
                    .context
                    .get(&first_iteration_key)
                    .cloned()
                    .unwrap_or(JsonValue::Null);

                debug!("Aggregated (FirstSuccess): {}", first_iteration_key);
                Ok(result)
            }

            AggregationMode::CollectAll => {
                // Collect all iteration outputs into an array
                let mut results = Vec::new();

                for iteration in 0..iterations_executed {
                    let iteration_key = format!("loop_{}_iter_{}", loop_id, iteration);
                    if let Some(value) = self.context.get(&iteration_key) {
                        results.push(value.clone());
                    }
                }

                debug!("Aggregated (CollectAll): {} iterations", results.len());
                Ok(JsonValue::Array(results))
            }
        }
    }

    /// Executes a sequence of strategy instructions recursively.
    ///
    /// This function handles the core execution logic for all instruction types:
    /// - Step: Execute a single agent step
    /// - Loop: Iteratively execute body instructions
    /// - Terminate: Check termination condition and exit early if met
    ///
    /// # Returns
    ///
    /// Returns `InstructionExecutionResult` indicating normal completion or early termination.
    #[instrument(skip(self))]
    async fn execute_instructions(
        &mut self,
        instructions: &[StrategyInstruction],
        steps_executed: &mut usize,
        loops_executed: &mut usize,
        terminations_triggered: &mut usize,
    ) -> Result<InstructionExecutionResult, OrchestratorError> {
        let mut final_result = JsonValue::Null;

        for instruction in instructions.iter() {
            match instruction {
                StrategyInstruction::Step(step) => {
                    debug!("Executing step: {}", step.step_id);

                    // Execute the step (simplified - full logic will be integrated later)
                    let intent = self.build_intent(step, &self.context).await?;

                    let agent = self.agents.get(&step.assigned_agent).ok_or_else(|| {
                        OrchestratorError::AgentNotFound(step.assigned_agent.clone())
                    })?;

                    // Note: Error handling for agent execution will be integrated later
                    // For now, we convert the error directly
                    let agent_output = agent.execute_dynamic(intent.into()).await?;

                    // Unwrap AgentOutput to get the JsonValue
                    let output = match agent_output {
                        AgentOutput::Success(json_value) => json_value,
                        AgentOutput::RequiresApproval { .. } => {
                            return Err(OrchestratorError::ExecutionFailed(
                                "Agent requires approval but orchestrator does not support HIL"
                                    .to_string(),
                            ));
                        }
                    };

                    // Store result in context
                    self.context
                        .insert(format!("step_{}_output", step.step_id), output.clone());

                    if let Some(ref output_key) = step.output_key {
                        self.context.insert(output_key.clone(), output.clone());
                    }

                    self.context
                        .insert("previous_output".to_string(), output.clone());

                    *steps_executed += 1;
                    final_result = output;
                }

                StrategyInstruction::Loop(loop_block) => {
                    debug!("Executing loop: {}", loop_block.loop_id);

                    // Track number of iterations actually executed
                    let mut iterations_executed = 0;

                    // Execute loop iterations
                    for iteration in 0..loop_block.max_iterations {
                        debug!(
                            "Loop {} iteration {}/{}",
                            loop_block.loop_id,
                            iteration + 1,
                            loop_block.max_iterations
                        );

                        *loops_executed += 1;

                        // Check global loop iteration limit
                        if *loops_executed > self.config.max_total_loop_iterations {
                            return Err(OrchestratorError::MaxLoopIterationsExceeded(
                                self.config.max_total_loop_iterations,
                            ));
                        }

                        // Execute loop body (using Box::pin for recursion)
                        let result = Box::pin(self.execute_instructions(
                            &loop_block.body,
                            steps_executed,
                            loops_executed,
                            terminations_triggered,
                        ))
                        .await?;

                        match result {
                            InstructionExecutionResult::Completed(output) => {
                                // Store iteration result
                                self.context.insert(
                                    format!("loop_{}_iter_{}", loop_block.loop_id, iteration),
                                    output.clone(),
                                );

                                iterations_executed += 1;
                                final_result = output;

                                // Evaluate condition to decide if loop should continue
                                let should_continue = if loop_block.condition_template.is_some() {
                                    self.evaluate_condition_template(
                                        &loop_block.condition_template,
                                        &self.context,
                                    )?
                                } else {
                                    true
                                };

                                if !should_continue {
                                    debug!(
                                        "Loop {} stopping early at iteration {}/{} (condition evaluated to false)",
                                        loop_block.loop_id,
                                        iteration + 1,
                                        loop_block.max_iterations
                                    );
                                    break;
                                }
                            }
                            InstructionExecutionResult::Terminated(output) => {
                                // Termination within loop - propagate it
                                return Ok(InstructionExecutionResult::Terminated(output));
                            }
                        }
                    }

                    // After loop completes, perform aggregation if configured
                    if let Some(ref aggregation) = loop_block.aggregation {
                        debug!(
                            "Aggregating loop {} results with mode {:?}",
                            loop_block.loop_id, aggregation.mode
                        );

                        let aggregated_value = self.aggregate_loop_results(
                            &loop_block.loop_id,
                            &aggregation.mode,
                            iterations_executed,
                        )?;

                        self.context
                            .insert(aggregation.output_key.clone(), aggregated_value.clone());
                        final_result = aggregated_value;
                    }
                }

                StrategyInstruction::Terminate(terminate) => {
                    debug!("Checking termination condition: {}", terminate.terminate_id);

                    // Evaluate termination condition
                    let should_terminate = self.evaluate_condition_template(
                        &terminate.condition_template,
                        &self.context,
                    )?;

                    if should_terminate {
                        info!("Termination triggered: {}", terminate.terminate_id);
                        *terminations_triggered += 1;

                        // Use final_output_template if provided
                        let termination_output = if let Some(ref template) =
                            terminate.final_output_template
                        {
                            use crate::prompt::render_prompt;
                            let rendered = render_prompt(template, &self.context).map_err(|e| {
                                OrchestratorError::TemplateRenderError(e.to_string())
                            })?;

                            JsonValue::String(rendered)
                        } else {
                            // Use current result if no template specified
                            final_result.clone()
                        };

                        return Ok(InstructionExecutionResult::Terminated(termination_output));
                    }
                }
            }
        }

        Ok(InstructionExecutionResult::Completed(final_result))
    }

    /// Determines the appropriate redesign strategy after an error.
    #[cfg(feature = "agent")]
    async fn determine_redesign_strategy(
        &self,
        error: &crate::agent::AgentError,
        failed_step_index: usize,
        goal: &str,
    ) -> Result<RedesignStrategy, OrchestratorError> {
        use crate::prompt::ToPrompt;
        use prompts::RedesignDecisionRequest;

        // Check if error is transient
        if error.is_transient() {
            return Ok(RedesignStrategy::Retry);
        }

        let strategy = self
            .strategy_map
            .as_ref()
            .ok_or_else(OrchestratorError::no_strategy)?;

        let request = RedesignDecisionRequest::new(
            goal.to_string(),
            failed_step_index,
            strategy.steps.len(),
            strategy.steps[failed_step_index].description.clone(),
            error.to_string(),
            self.format_completed_steps(failed_step_index),
        );

        let prompt = request.to_prompt();

        debug!("Redesign decision prompt:\n{}", prompt);

        // Ask internal agent for decision with fallback handling
        let decision = match self.internal_agent.execute(prompt.into()).await {
            Ok(d) => d,
            Err(e) => {
                error!(
                    "Internal agent failed to determine redesign strategy: {}",
                    e
                );
                warn!("Attempting fallback: defaulting to FullRegenerate strategy");

                // Fallback attempt: Try once more with a simpler prompt
                let fallback_prompt = format!(
                    "The previous step failed with error: {}. Should we regenerate the entire strategy? Answer with 'FULL' or 'TACTICAL'.",
                    error
                );

                match self.internal_agent.execute(fallback_prompt.into()).await {
                    Ok(d) => d,
                    Err(fallback_error) => {
                        error!(
                            "Internal agent failed on fallback attempt: {}",
                            fallback_error
                        );
                        return Err(OrchestratorError::InternalAgentUnrecoverable(
                            fallback_error.to_string(),
                        ));
                    }
                }
            }
        };

        let decision_upper = decision.trim().to_uppercase();

        if decision_upper.contains("RETRY") {
            Ok(RedesignStrategy::Retry)
        } else if decision_upper.contains("TACTICAL") {
            Ok(RedesignStrategy::TacticalRedesign)
        } else if decision_upper.contains("FULL") {
            Ok(RedesignStrategy::FullRegenerate)
        } else {
            warn!(
                "Unexpected redesign decision: {}. Defaulting to FULL",
                decision
            );
            Ok(RedesignStrategy::FullRegenerate)
        }
    }

    /// Determines the appropriate redesign strategy (stub).
    #[cfg(not(all(feature = "agent", feature = "derive")))]
    async fn determine_redesign_strategy(
        &self,
        error: &crate::agent::AgentError,
        _failed_step_index: usize,
        _goal: &str,
    ) -> Result<RedesignStrategy, OrchestratorError> {
        if error.is_transient() {
            Ok(RedesignStrategy::Retry)
        } else {
            Ok(RedesignStrategy::FullRegenerate)
        }
    }

    /// Performs tactical redesign of remaining steps.
    #[cfg(feature = "agent")]
    async fn tactical_redesign(
        &mut self,
        error: &crate::agent::AgentError,
        failed_step_index: usize,
    ) -> Result<(), OrchestratorError> {
        use crate::prompt::ToPrompt;
        use prompts::TacticalRedesignRequest;

        let strategy = self
            .strategy_map
            .as_ref()
            .ok_or_else(OrchestratorError::no_strategy)?
            .clone();

        let request = TacticalRedesignRequest::new(
            strategy.goal.clone(),
            serde_json::to_string_pretty(&strategy)
                .map_err(|e| OrchestratorError::StrategyGenerationFailed(e.to_string()))?,
            failed_step_index,
            strategy.steps[failed_step_index].description.clone(),
            error.to_string(),
            self.format_completed_steps(failed_step_index),
            self.format_agent_list(),
        );

        let prompt = request.to_prompt();

        debug!("Tactical redesign prompt:\n{}", prompt);

        // Get new steps from LLM with fallback handling
        let response = match self.internal_agent.execute(prompt.into()).await {
            Ok(r) => r,
            Err(e) => {
                error!("Internal agent failed during tactical redesign: {}", e);
                warn!("Attempting fallback: requesting simpler redesign");

                // Fallback attempt: Try with a simpler prompt
                let fallback_prompt = format!(
                    "Generate alternative steps to replace step {} which failed with: {}. Return a JSON array of steps.",
                    failed_step_index + 1,
                    error
                );

                match self.internal_agent.execute(fallback_prompt.into()).await {
                    Ok(r) => r,
                    Err(fallback_error) => {
                        error!(
                            "Internal agent failed on fallback attempt during tactical redesign: {}",
                            fallback_error
                        );
                        return Err(OrchestratorError::InternalAgentUnrecoverable(
                            fallback_error.to_string(),
                        ));
                    }
                }
            }
        };

        // Extract JSON from response (handles markdown code blocks)
        let json_str = crate::extract_json(&response).map_err(|e| {
            error!(
                "Failed to extract JSON from tactical redesign response. Error: {}\nResponse was: {}",
                e,
                response
            );
            OrchestratorError::StrategyGenerationFailed(format!(
                "Failed to extract JSON from redesign response: {}",
                e
            ))
        })?;

        // Parse JSON array of StrategyStep
        let new_steps: Vec<StrategyStep> = serde_json::from_str(&json_str).map_err(|e| {
            error!(
                "Failed to parse redesigned steps. Error: {}\nJSON was: {}",
                e, json_str
            );
            OrchestratorError::StrategyGenerationFailed(format!(
                "Failed to parse redesigned steps: {}",
                e
            ))
        })?;

        info!("Tactical redesign generated {} new steps", new_steps.len());

        // Update strategy: keep completed steps, replace from failed_step_index onwards
        if let Some(ref mut strategy) = self.strategy_map {
            strategy.steps.truncate(failed_step_index);
            strategy.steps.extend(new_steps);
        }

        Ok(())
    }

    /// Performs tactical redesign (stub).
    #[cfg(not(all(feature = "agent", feature = "derive")))]
    async fn tactical_redesign(
        &mut self,
        _error: &crate::agent::AgentError,
        _failed_step_index: usize,
    ) -> Result<(), OrchestratorError> {
        Err(OrchestratorError::ExecutionFailed(
            "Tactical redesign not available without agent and derive features".to_string(),
        ))
    }

    /// Performs full strategy regeneration from scratch.
    #[cfg(feature = "agent")]
    async fn full_regenerate(
        &mut self,
        error: &crate::agent::AgentError,
        failed_step_index: usize,
    ) -> Result<(), OrchestratorError> {
        use crate::prompt::ToPrompt;
        use prompts::FullRegenerateRequest;

        let task = self
            .current_task
            .as_ref()
            .ok_or_else(|| {
                OrchestratorError::Other("No current task available for regeneration".to_string())
            })?
            .clone();

        let strategy = self
            .strategy_map
            .as_ref()
            .ok_or_else(OrchestratorError::no_strategy)?
            .clone();

        let request = FullRegenerateRequest::new(
            task,
            self.format_agent_list(),
            self.blueprint.description.clone(),
            self.blueprint.graph.clone(),
            serde_json::to_string_pretty(&strategy)
                .map_err(|e| OrchestratorError::StrategyGenerationFailed(e.to_string()))?,
            format!(
                "Step {} ({}) failed with error: {}",
                failed_step_index + 1,
                strategy.steps[failed_step_index].description,
                error
            ),
            self.format_completed_steps(failed_step_index),
        );

        let prompt = request.to_prompt();

        debug!("Full regeneration prompt:\n{}", prompt);

        // Generate completely new strategy
        let new_strategy = self
            .internal_json_agent
            .execute(prompt.into())
            .await
            .map_err(|e| OrchestratorError::StrategyGenerationFailed(e.to_string()))?;

        info!(
            "Full regeneration completed with {} steps",
            new_strategy.steps.len()
        );

        self.strategy_map = Some(new_strategy);
        Ok(())
    }

    /// Performs full regeneration (stub).
    #[cfg(not(all(feature = "agent", feature = "derive")))]
    async fn full_regenerate(
        &mut self,
        _error: &crate::agent::AgentError,
        _failed_step_index: usize,
    ) -> Result<(), OrchestratorError> {
        Err(OrchestratorError::ExecutionFailed(
            "Full regeneration not available without agent and derive features".to_string(),
        ))
    }

    /// Clears the current strategy and context (useful for re-execution).
    pub fn reset(&mut self) {
        self.strategy_map = None;
        self.context.clear();
        self.current_task = None;
    }
}

/// Counts the number of Step instructions in a list of instructions.
///
/// This recursively counts Step instructions inside Loop bodies.
#[allow(dead_code)]
fn count_steps_in_instructions(instructions: &[StrategyInstruction]) -> usize {
    use crate::orchestrator::strategy::StrategyInstruction;

    let mut count = 0;
    for instruction in instructions {
        match instruction {
            StrategyInstruction::Step(_) => {
                count += 1;
            }
            StrategyInstruction::Loop(loop_block) => {
                // Recursively count steps in loop body
                count += count_steps_in_instructions(&loop_block.body);
            }
            StrategyInstruction::Terminate(_) => {
                // Terminate instructions don't count as steps
            }
        }
    }
    count
}

#[cfg(all(test, feature = "agent"))]
mod tests {
    use super::*;
    use crate::agent::impls::ClaudeCodeAgent;
    use crate::agent::{Agent, AgentError, Payload};
    use async_trait::async_trait;
    use tokio::runtime::Runtime;

    #[test]
    fn test_orchestrator_creation() {
        let blueprint = BlueprintWorkflow::new("Test workflow".to_string());
        let orch = Orchestrator::new(blueprint);
        // InnerValidatorAgent is automatically registered
        assert_eq!(orch.list_agents().len(), 1);
        assert!(orch.get_agent("InnerValidatorAgent").is_some());
    }

    #[test]
    fn test_add_agent() {
        let blueprint = BlueprintWorkflow::new("Test".to_string());
        let mut orch = Orchestrator::new(blueprint);

        orch.add_agent(ClaudeCodeAgent::new());
        // InnerValidatorAgent (auto-registered) + ClaudeCodeAgent
        assert_eq!(orch.list_agents().len(), 2);
        assert!(orch.get_agent("ClaudeCodeAgent").is_some());
        assert!(orch.get_agent("InnerValidatorAgent").is_some());
    }

    #[test]
    fn test_format_agent_list() {
        let blueprint = BlueprintWorkflow::new("Test".to_string());
        let mut orch = Orchestrator::new(blueprint);

        orch.add_agent(ClaudeCodeAgent::new());
        let list = orch.format_agent_list();
        assert!(list.contains("ClaudeCodeAgent"));
    }

    #[test]
    fn test_context_initially_empty() {
        let blueprint = BlueprintWorkflow::new("Test".to_string());
        let orch = Orchestrator::new(blueprint);

        // Initially context should be empty
        assert!(orch.context().is_empty());
        assert!(orch.get_step_output("step_1").is_none());
        assert!(orch.get_all_step_outputs().is_empty());
    }

    #[test]
    fn test_context_accessors_available() {
        let blueprint = BlueprintWorkflow::new("Test".to_string());
        let orch = Orchestrator::new(blueprint);

        // Verify all accessor methods are callable (main fix - these were not accessible before)
        let _context = orch.context();
        let _step_output = orch.get_step_output("step_1");
        let _step_prompt = orch.get_step_output_prompt("step_1");
        let _all_outputs = orch.get_all_step_outputs();

        // Before this fix, the above lines would not compile because context was private
        // The test passes if it compiles successfully (no assertion needed)
    }

    #[test]
    fn test_set_strategy_map() {
        let blueprint = BlueprintWorkflow::new("Test".to_string());
        let mut orch = Orchestrator::new(blueprint);

        // Initially no strategy
        assert!(orch.strategy_map().is_none());

        // Set a predefined strategy
        let mut strategy = StrategyMap::new("Test goal".to_string());
        strategy.add_step(StrategyStep::new(
            "step_1".to_string(),
            "Test step".to_string(),
            "ClaudeCodeAgent".to_string(),
            "Test intent".to_string(),
            "Test output".to_string(),
        ));

        orch.set_strategy_map(strategy.clone());

        // Verify strategy is set
        assert!(orch.strategy_map().is_some());
        assert_eq!(orch.strategy_map().unwrap().goal, "Test goal");
        assert_eq!(orch.strategy_map().unwrap().elements.len(), 1);
        // Verify the first element is a Step
        match &orch.strategy_map().unwrap().elements[0] {
            crate::orchestrator::StrategyInstruction::Step(step) => {
                assert_eq!(step.description, "Test step");
            }
            _ => panic!("Expected first element to be a Step"),
        }
    }

    #[test]
    fn test_strategy_map_getter() {
        let blueprint = BlueprintWorkflow::new("Test".to_string());
        let mut orch = Orchestrator::new(blueprint);

        // Initially None
        assert!(orch.strategy_map().is_none());

        // After setting
        let strategy = StrategyMap::new("Goal".to_string());
        orch.set_strategy_map(strategy);
        assert!(orch.strategy_map().is_some());
    }

    #[test]
    fn test_extract_placeholders_double_braces() {
        let template = "Process {{ previous_output }} for {{ task }}";
        let placeholders = Orchestrator::extract_placeholders(template);

        assert_eq!(placeholders.len(), 2);
        assert!(placeholders.contains(&"previous_output".to_string()));
        assert!(placeholders.contains(&"task".to_string()));
    }

    #[test]
    fn test_extract_placeholders_with_spaces() {
        let template = "{{  name  }} and {{value}}";
        let placeholders = Orchestrator::extract_placeholders(template);

        assert_eq!(placeholders.len(), 2);
        assert!(placeholders.contains(&"name".to_string()));
        assert!(placeholders.contains(&"value".to_string()));
    }

    #[test]
    fn test_extract_placeholders_no_duplicates() {
        let template = "{{ name }} and {{ name }} again";
        let placeholders = Orchestrator::extract_placeholders(template);

        assert_eq!(placeholders.len(), 1);
        assert_eq!(placeholders[0], "name");
    }

    #[test]
    fn test_extract_placeholders_empty_template() {
        let template = "No placeholders here";
        let placeholders = Orchestrator::extract_placeholders(template);

        assert_eq!(placeholders.len(), 0);
    }

    #[test]
    fn test_evaluate_condition_template_true() {
        let mut context = HashMap::new();
        context.insert("approved".to_string(), JsonValue::Bool(true));

        let orch = create_test_orchestrator();

        // Template that evaluates to "true"
        let template = Some("{{ approved }}".to_string());
        let result = orch
            .evaluate_condition_template(&template, &context)
            .unwrap();

        assert!(result);
    }

    #[test]
    fn test_evaluate_condition_template_false() {
        let mut context = HashMap::new();
        context.insert("approved".to_string(), JsonValue::Bool(false));

        let orch = create_test_orchestrator();

        // Template that evaluates to "false"
        let template = Some("{{ approved }}".to_string());
        let result = orch
            .evaluate_condition_template(&template, &context)
            .unwrap();

        assert!(!result);
    }

    #[test]
    fn test_evaluate_condition_template_comparison() {
        let mut context = HashMap::new();
        context.insert("count".to_string(), JsonValue::Number(5.into()));

        let orch = create_test_orchestrator();

        // Template with comparison that evaluates to "true"
        let template = Some("{% if count > 3 %}true{% else %}false{% endif %}".to_string());
        let result = orch
            .evaluate_condition_template(&template, &context)
            .unwrap();

        assert!(result);
    }

    #[test]
    fn test_evaluate_condition_template_none() {
        let context = HashMap::new();
        let orch = create_test_orchestrator();

        // None template should return false
        let result = orch.evaluate_condition_template(&None, &context).unwrap();

        assert!(!result);
    }

    #[test]
    fn test_evaluate_condition_template_case_insensitive() {
        let context = HashMap::new();
        let orch = create_test_orchestrator();

        // Test various case variations of "true"
        for true_variant in &["true", "True", "TRUE", "TrUe"] {
            let template = Some(true_variant.to_string());
            let result = orch
                .evaluate_condition_template(&template, &context)
                .unwrap();
            assert!(result, "Expected '{}' to evaluate to true", true_variant);
        }
    }

    #[test]
    fn test_aggregate_loop_results_last_success() {
        use crate::orchestrator::strategy::AggregationMode;

        let mut orch = create_test_orchestrator();

        // Simulate 3 loop iterations with stored results
        orch.context.insert(
            "loop_test_iter_0".to_string(),
            JsonValue::String("first".to_string()),
        );
        orch.context.insert(
            "loop_test_iter_1".to_string(),
            JsonValue::String("second".to_string()),
        );
        orch.context.insert(
            "loop_test_iter_2".to_string(),
            JsonValue::String("third".to_string()),
        );

        let result = orch
            .aggregate_loop_results("test", &AggregationMode::LastSuccess, 3)
            .unwrap();

        assert_eq!(result, JsonValue::String("third".to_string()));
    }

    #[test]
    fn test_aggregate_loop_results_first_success() {
        use crate::orchestrator::strategy::AggregationMode;

        let mut orch = create_test_orchestrator();

        // Simulate 3 loop iterations with stored results
        orch.context.insert(
            "loop_test_iter_0".to_string(),
            JsonValue::String("first".to_string()),
        );
        orch.context.insert(
            "loop_test_iter_1".to_string(),
            JsonValue::String("second".to_string()),
        );
        orch.context.insert(
            "loop_test_iter_2".to_string(),
            JsonValue::String("third".to_string()),
        );

        let result = orch
            .aggregate_loop_results("test", &AggregationMode::FirstSuccess, 3)
            .unwrap();

        assert_eq!(result, JsonValue::String("first".to_string()));
    }

    #[test]
    fn test_aggregate_loop_results_collect_all() {
        use crate::orchestrator::strategy::AggregationMode;

        let mut orch = create_test_orchestrator();

        // Simulate 3 loop iterations with stored results
        orch.context.insert(
            "loop_test_iter_0".to_string(),
            JsonValue::String("first".to_string()),
        );
        orch.context.insert(
            "loop_test_iter_1".to_string(),
            JsonValue::String("second".to_string()),
        );
        orch.context.insert(
            "loop_test_iter_2".to_string(),
            JsonValue::String("third".to_string()),
        );

        let result = orch
            .aggregate_loop_results("test", &AggregationMode::CollectAll, 3)
            .unwrap();

        assert_eq!(
            result,
            JsonValue::Array(vec![
                JsonValue::String("first".to_string()),
                JsonValue::String("second".to_string()),
                JsonValue::String("third".to_string()),
            ])
        );
    }

    #[test]
    fn test_aggregate_loop_results_empty_iterations() {
        use crate::orchestrator::strategy::AggregationMode;

        let orch = create_test_orchestrator();

        // Test with zero iterations
        let result_last = orch
            .aggregate_loop_results("test", &AggregationMode::LastSuccess, 0)
            .unwrap();
        let result_first = orch
            .aggregate_loop_results("test", &AggregationMode::FirstSuccess, 0)
            .unwrap();
        let result_all = orch
            .aggregate_loop_results("test", &AggregationMode::CollectAll, 0)
            .unwrap();

        assert_eq!(result_last, JsonValue::Null);
        assert_eq!(result_first, JsonValue::Null);
        assert_eq!(result_all, JsonValue::Array(vec![]));
    }

    #[test]
    fn test_count_steps_in_instructions_simple() {
        use crate::orchestrator::strategy::{StrategyInstruction, StrategyStep};

        let instructions = vec![
            StrategyInstruction::Step(StrategyStep {
                step_id: "step1".to_string(),
                description: "Test step 1".to_string(),
                assigned_agent: "agent1".to_string(),
                intent_template: "Do something".to_string(),
                expected_output: "Result 1".to_string(),
                requires_validation: false,
                output_key: None,
            }),
            StrategyInstruction::Step(StrategyStep {
                step_id: "step2".to_string(),
                description: "Test step 2".to_string(),
                assigned_agent: "agent2".to_string(),
                intent_template: "Do something else".to_string(),
                expected_output: "Result 2".to_string(),
                requires_validation: false,
                output_key: None,
            }),
        ];

        let count = count_steps_in_instructions(&instructions);
        assert_eq!(count, 2);
    }

    #[test]
    fn test_count_steps_in_instructions_with_loop() {
        use crate::orchestrator::strategy::{LoopBlock, StrategyInstruction, StrategyStep};

        let loop_body = vec![StrategyInstruction::Step(StrategyStep {
            step_id: "step1".to_string(),
            description: "Loop step".to_string(),
            assigned_agent: "agent1".to_string(),
            intent_template: "Do something".to_string(),
            expected_output: "Loop result".to_string(),
            requires_validation: false,
            output_key: None,
        })];

        let instructions = vec![
            StrategyInstruction::Step(StrategyStep {
                step_id: "step_before".to_string(),
                description: "Before loop".to_string(),
                assigned_agent: "agent1".to_string(),
                intent_template: "Before".to_string(),
                expected_output: "Before result".to_string(),
                requires_validation: false,
                output_key: None,
            }),
            StrategyInstruction::Loop(LoopBlock {
                loop_id: "loop1".to_string(),
                description: Some("Test loop".to_string()),
                loop_type: None,
                max_iterations: 3,
                condition_template: None,
                body: loop_body,
                aggregation: None,
            }),
            StrategyInstruction::Step(StrategyStep {
                step_id: "step_after".to_string(),
                description: "After loop".to_string(),
                assigned_agent: "agent1".to_string(),
                intent_template: "After".to_string(),
                expected_output: "After result".to_string(),
                requires_validation: false,
                output_key: None,
            }),
        ];

        // Should count: 1 (before) + 1 (loop body) + 1 (after) = 3
        let count = count_steps_in_instructions(&instructions);
        assert_eq!(count, 3);
    }

    #[test]
    fn test_count_steps_in_instructions_with_terminate() {
        use crate::orchestrator::strategy::{
            StrategyInstruction, StrategyStep, TerminateInstruction,
        };

        let instructions = vec![
            StrategyInstruction::Step(StrategyStep {
                step_id: "step1".to_string(),
                description: "Test step".to_string(),
                assigned_agent: "agent1".to_string(),
                intent_template: "Do something".to_string(),
                expected_output: "Result".to_string(),
                requires_validation: false,
                output_key: None,
            }),
            StrategyInstruction::Terminate(TerminateInstruction {
                terminate_id: "term1".to_string(),
                description: Some("Early termination".to_string()),
                condition_template: Some("{{ done }}".to_string()),
                final_output_template: None,
            }),
        ];

        // Terminate doesn't count as a step
        let count = count_steps_in_instructions(&instructions);
        assert_eq!(count, 1);
    }

    #[test]
    fn test_loop_without_condition_runs_max_iterations() {
        let mut orch = Orchestrator::new(BlueprintWorkflow::new("Loop workflow".to_string()));
        let agent = RecordingAgent;
        let agent_name = Agent::name(&agent);
        orch.add_agent(agent);

        let mut strategy = StrategyMap::new("Loop until max iterations".to_string());
        strategy.add_instruction(StrategyInstruction::Loop(LoopBlock {
            loop_id: "loop_1".to_string(),
            description: None,
            loop_type: None,
            max_iterations: 3,
            condition_template: None,
            body: vec![StrategyInstruction::Step(StrategyStep::new(
                "loop_step".to_string(),
                "Execute loop step".to_string(),
                agent_name.clone(),
                "Run loop step".to_string(),
                "Loop output".to_string(),
            ))],
            aggregation: None,
        }));

        orch.set_strategy_map(strategy);
        orch.config.max_total_loop_iterations = 10;
        orch.config.enable_fast_path_intent_generation = true;

        let runtime = Runtime::new().expect("runtime");
        let result = runtime.block_on(orch.execute("test loop"));

        assert_eq!(
            result.status,
            OrchestrationStatus::Success,
            "error: {:?}",
            result.error_message
        );
        assert_eq!(result.loops_executed, 3);
        assert_eq!(result.steps_executed, 3);
        assert_eq!(result.terminations_triggered, 0);
    }

    #[test]
    fn test_terminate_instruction_counts_actual_steps() {
        let mut orch = Orchestrator::new(BlueprintWorkflow::new("Terminate workflow".to_string()));
        let agent = RecordingAgent;
        let agent_name = Agent::name(&agent);
        orch.add_agent(agent);

        let mut strategy = StrategyMap::new("Terminate early".to_string());
        strategy.add_instruction(StrategyInstruction::Step(StrategyStep::new(
            "step_1".to_string(),
            "First step".to_string(),
            agent_name.clone(),
            "Do work".to_string(),
            "Output".to_string(),
        )));
        strategy.add_instruction(StrategyInstruction::Terminate(TerminateInstruction {
            terminate_id: "stop".to_string(),
            description: Some("Stop early".to_string()),
            condition_template: Some("true".to_string()),
            final_output_template: None,
        }));
        strategy.add_instruction(StrategyInstruction::Step(StrategyStep::new(
            "step_2".to_string(),
            "Should not run".to_string(),
            agent_name,
            "Do more work".to_string(),
            "More output".to_string(),
        )));

        orch.set_strategy_map(strategy);
        orch.config.enable_fast_path_intent_generation = true;

        let runtime = Runtime::new().expect("runtime");
        let result = runtime.block_on(orch.execute("test terminate"));

        assert_eq!(
            result.status,
            OrchestrationStatus::Success,
            "error: {:?}",
            result.error_message
        );
        assert_eq!(result.terminations_triggered, 1);
        assert_eq!(result.steps_executed, 1);
    }

    fn create_test_orchestrator() -> Orchestrator {
        let blueprint =
            BlueprintWorkflow::new("Test workflow for condition evaluation".to_string());
        Orchestrator::new(blueprint)
    }

    #[derive(Clone, Default)]
    struct RecordingAgent;

    #[async_trait]
    impl Agent for RecordingAgent {
        type Output = JsonValue;

        fn expertise(&self) -> &str {
            "Test agent"
        }

        async fn execute(&self, _intent: Payload) -> Result<Self::Output, AgentError> {
            Ok(JsonValue::String("ok".to_string()))
        }
    }
}
